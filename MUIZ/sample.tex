\documentclass[12pt]{article}

\usepackage[english]{babel}


\usepackage[a4paper,top=6cm,bottom=6cm,left=3cm,right=3cm,marginparwidth=3cm]{geometry}

\usepackage{amsmath}


\begin{document}
\begin{titlepage}
\begin{center}
\vspace*{1cm}


		\textbf{LAPLACE TRANSFORMATION METHOD OF SOLVING SYSTEM OF VOLTERRA INTEGRAL EQUATION}


\vspace{0.5cm}

\textbf{BY}

\vspace{1.5cm}

\textbf{ISHOLA ABDULMUIZ ADESHINA}

\textbf{MATRICULATION NUMBER: 17/30GQ029}

\vfill

\textbf{A PROJECT SUBMITTED TO THE DEPARTMENT OF MATHEMATICS, FACULTY OF PHYSICAL SCIENCE, UNIVERSITY OF ILORIN, ILORIN, NIGERIA.IN PARTIAL FULFILLMENT OF THE REQUIREMENTS FOR THE AWARD OF THE BACHELOR OF SCIENCE DEGREE IN MATHEMATICS}

\vspace{0.8cm}

\vfill

\textbf{OCTOBER 2022}

\end{center}
\end{titlepage}

\addcontentsline{toc}{section}{Dedication}
\textbf{DEDICATION}\\

This work is dedicated to the Glory of God for His infinite mercy and guidance over me.

My ever caring and loving father, Alhaji M.A Ishola for his continuous guidance and support.

My sweet mother Alhaja A.M Ishola for her care, love, advise and motherly role and to all the people that made this project a great success.

\newpage
\addcontentsline{toc}{section}{Acknowledgement}
\textbf{ACKNOWLEDGEMENT}\\

Firstly, I will give glory to God for his abundant blessings and guidance throughout my stay in school and for giving strength to face all tasks.

	An academic pursuit is a challenging task that requires all encouragement, proper guidance, direction and support. To this end I wish to express my sincere and profound gratitude to my level advisor and supervisor, Dr. K.A Bello, who supervised and carefully guided the eventual write up of this project.

	My sincere gratitude to my parents Alhaji M.A Ishola and Alhaja A.M Ishola for their continuous love, moral support, prayer, advice and financial support in all my academic undertakings. May you reap the fruit of your labor (Amin).

	I would also like to express my appreciation to my numerous lecturers, first of all the H.O.D Professor K Rauf, Professor O.A Taiwo, Dr. Usamot, Dr. Aderinto, Dr. Isa and many of my lecturers I’m not able to write. I thank you all for your immense advise, support and contribution towards the completion of my programme.

	I also want to express my deep and sincere appreciation to my sisters, Muftiat and Mufeedah for their moral support and companionship.

	Further appreciation goes to my friends, Sa’ad Muhammed, Adebayo Muhammed, Adejumo Lekan, Muhammed Teslim, Tajudeen Mustapha, and others whom I’m not opportuned to mention their names, thank you all for your constant advice, encouragement, love and making my stay on campus worthwhile.

	Finally, to God Almighty who made everythimg possible for me.\\

\newpage
\begin{abstract}
This project discusses the numerical solution of the system of Volterra integral equations by using Laplace transform method. The Volterra integral equations is a method that can be used to solve initial value problems and integral equations as well,it transforms linear differential equations into algebraic equations and convolution into multiplication. Laplace is also an integral transform that converts a function of a real variable (x) to a function of a complex variable (S).
\end{abstract}
\newpage
\tableofcontents
\newpage
\section{INTRODUCTION}
\subsection{History of integral equation 1888-1903}
J. Fourier (1768-1830) is the initiator of the theory of integral equations. A term integral equation first suggested by Du Bois-Reymond in 1888. Du Bois-Reymond define an integral equation is understood an equation in which the unknown function occurs under one or more signs of definite integration. Late eighteenth and early ninetieth century Laplace, Fourier, Poission, Liouville and Abel studies some special type of integral equation. The pioneering systematic investigations goes back to late nineteenth and early twentieth century work of Volterra, Fredholm and Hilbert. In 1887, Volterra published a series of famous papers in which he singled out the notion of a functional and pioneered in the development of a theory of functionals in theory of linear integral equation of special type. Fredholm presented the fundamentals of the Fredholm integral equation theory in a paper published in 1903 in the Acta Mathematica. This paper became famous almost overnight and soon took its rightful place among the gems of modern mathematics. Hilbert followed Fredholm’s famous paperwith a series of papers in the Nachrichten of the GUttingen Academy.
\\

(Subrahamanyam Upadhyay and K. N. Rai (November 4, 2015))
\\

\section{Integral equation}
Integral equation is an equation in which the unknown, say a function of a numerical variable, occurs under an integral. That means a functional equation involving the unknown function under one or more integrals. For example,
\\

$y(x) = f(x) + 5$ \(\int_{0}^{1} e^{t+x} y(t)dt\)

\subsection{Volterra Integral equation}
Second kind of Linear Volterra integral equation defined by,
\\

$y(x) = f(x) + \lambda$ \(\int_{x_0}^{x} K(t,x)y(t)dt\)\\

where f(x),K(t,x) are known functions and y(x) is the unknown function and $\lambda$ is a numerical parameter.

Second kind of non-linear Volterra integral equation defined by 
\\

$y(x) = f(x) + \lambda$ \(\int_{x_0}^{x}K_0(t,x,y(t))dt\)\\

where $K_0(t, x, y(t)) 6 =K(t, x)y(t)$. First kind of Linear Volterra integral equa-tion defined by
\\

$f(x) + \lambda$ \(\int_{x_0}^{x}K(t,x)y(t)dt\) $= 0$\\

First kind of non - linear Volterra integral equation defined by,
\\

$f(x) + \lambda$ \(\int_{x_0}^{x}K_0(t,x)y(t)dt\) $= 0$\\

\subsection{Fredholm Integral equation}
Second kind of Linear Fredholm integral equation defined by,
\\

$y(x) = f(x) + \lambda$ \(\int_{x_0}^{x_1} K(t,x)y(t)dt\)\\

where f(x),K(t,x) are known functions and y(x) is the unknown fuction and $\lambda$ is a numerical parameter.

Second kind of non-linear Fredholm integral equation defined by 
\\

$y(x) = f(x) + \lambda$ \(\int_{x_0}^{x_1}K_0(t,x,y(t))dt\)\\

where $K_0(t, x, y(t)) 6 =K(t, x)y(t)$. First kind of Linear Fredholm integral equa-tion defined by
\\

$f(x) + \lambda$ \(\int_{x_0}^{x_1}K(t,x)y(t)dt\) $= 0$\\

First kind of non - linear Fredholm integral equation defined by,
\\

$f(x) + \lambda$ \(\int_{x_0}^{x_1}K_0(t,x)y(t)dt\) $= 0$\\

\textbf{Remarks} If $f(x) = 0$, then above defined Volterra and Fredholm Integral equations are called homogeneous type otherwise non homogeneous. Main difference between Volterra and Fredholm Integral equations are range of integration in the integral equation.

\subsection{Classification of Integral Equations}
\par Integral equations are classified according to three different dichotomies:\\
\\
\textbf{I}   Limits of Integration
\par (a) \textbf{both fixed}: Fredholm equation
\par (b) \textbf{one variable}: Volterra equation\\
\\
\textbf{II}   Placement of unknown function
\par (a) \textbf{only inside integral}: first kind
\par (b) \textbf{both inside and outside integral}: second kind\\
\\
\textbf{III} Nature of known function f
\par (a) \textbf{identically zero}: homogeneous
\par(b) \textbf{not identically zero}: inhomogeneous\\

Integral equations are important in many applications. Problems in which integral equations are encountered including \textbf{radiative transfer}, and the \textbf{oscillation} of a string, membrane, or axle. Oscillation problems may also be solved as \textbf{differential equations}.
\newpage
\subsection{The Connection Between Differential and Integral Equations (First-Order)}
Consider the differential equation (initial value problem)\\
$y'(x) = f(x,y)$	\textbf{(1.6.1)}\\
$y(x_0) = y_0$\\
By integrating $x_0 to x$, we obtain;

\[\int_{x_0}^{x} y'(t)dt = \int{x_0}^{x} f(t,y)dt\] ,
i.e,

$y(x) = y_0$ + \(\int_{x_0}^{x} f(t,y)dt\).		\textbf{(1.6.2)}\\
\\

On the other hand, if \textbf{(1.6.2)} holds, we see that $y(x_0) = y_0$, and\\
\\
$y'(x) = f(x,y)$,\\
which implies that \textbf{(1.6.1)} holds! Thus the problems \textbf{(1.6.1)} and \textbf{(1.6.2)} are equivalent.

In fact, it is possible to formulate many initial and boundary value problems as integral equations amd vice versa.

\subsection{The Connection Between Differential and Integral Equations (Second-Order)}
Assume that we want to solve the initial value problem\\
$u"(x) + u(x)q(x) = f(x), x>a$,		\textbf{(1.7.1)}\\
$u(a) = u_0,		u'(a) = u_1.$\\
\\
We integrate the equation from a to x and get\\
$u'(x) - u_1$ = \(\int_{a}^{x} [f(y) - q(y)u(y)]dy\),\\
\\
and another integration yields\\
\(\int_{a}^{x} u'(s)ds = \int_{a}^{x} u_1ds\) + \(\int_{a}^{x}\)\(\int_{a}^{x} [f(y) - q(y)u(y)]dyds\)\\
\\
we get;\\
\\
$u(x) - u_0 = u_1(x-a)$ + \(\int_{a}^{x} [f(y) - q(y)u(y)](x - y)dy\),\\
\\
which we can write as,\\
\\
$u(x) = u_0 + u_1(x-a)$ + \(\int_{a}^{x} f(y)(x - y)dy\) + \(\int_{a}^{x} q(y)(y - x)u(y)dy\)\\
\\
$= F(x)$ + \(\int_{a}^{x} k(x,y)u(y)dy\),\\
where,\\
$F(x) = u_0 + u_1(x - a)$ + \(\int_{a}^{x} f(y)(x - y)dy\), and\\
$k(x,y) = q(y)(y - x).$\\
\par This implies that \textbf{(1.7.1)} can be written as \textbf{Volterra equation}\\
$u(x) = F(x)$ + \(\int_{a}^{x} k(x,y)u(y)dy\).\\
\newpage
\section{Subject Matter}
\section{Volterra Integral Equation}
In mathematics, the Volterra integral equations are a special type of integral equations. They are divided into two groups referred to as the first and the second kind.

A linear Volterra equation of the first kind is;\\
 f(t) = \(\int_{a}^{t} K(t, s) x(s) ds\)

where f is a given function and x is an unknown function to be solved for. A linear Volterra equation of the second kind is;\\

x(t) = f(t) + \(\int_{a}^{t} K(t,s) x(s) ds\).\\

In operator theory, and in Fredholm theory, the corresponding operators are called Volterra operators. A useful method to solve such equations, the Adomian decomposition method, is due to George Adomian.

A linear Volterra integral equation is a convolution equation if,\\

x(t) = f(t) + \(\int_{t_{0}}^{t} K(t - s) x(s) ds\).\\

The function K in the integral is called the kernel. Such equations can be analyzed and solved by means of Laplace transform techniques.

The Volterra integral equations were introduced by Vito Volterra and then studied by Traian Lalescu in his 1908 thesis, Sur les équations de Volterra, written under the direction of Émile Picard. In 1911, Lalescu wrote the first book ever on integral equations.

Volterra integral equations find application in demography, the study of viscoelastic materials, and in actuarial science through the renewal equation.
\subsection{Conversion of Volterra equation of the first kind to the second kind}
A linear Volterra equation of the first kind can always be reduced to a linear Volterra equation of the second kind, assuming that $K(t,t)\neq{0}$. Taking the derivative of the first kind Volterra equation gives us:\\

$\frac{df}{dt}$ = \(\int_{a}^{t} \frac{\partial K}{\partial t} x(s) ds\)\\

Divivding through by K(t,t) yields:\\

x(t) = $\frac{1}{K(t,t)} \frac{df}{dt}$ - \(\int_{a}^{t} \frac{1}{K(t,t} \frac{\partial K}{\partial t} x(s) ds\)\\

Defining $\overline{f}(t)$ = $\frac{1}{K(t,t} \frac{df}{dt}$ and $\overline{K}(t,s)$ = -$\frac{1}{K(t,t)} \frac{\partial K}{\partial t}$ completes the transformation of the first kind equation into a linear Volterra equation of the second kind.

\subsection{Volterra-Fredholm Integral Equations}
The Volterra-Fredholm integral equations [6,7] arise from parabolic boundary value problems, from the mathematical modelling of the spatio-temporal development of an epidemic, and from various physical and biological models.
The Volterra-Fredholm integral equations appear in the literature in two forms, namely;\\

u(x) = f(x) + $\lambda_{1}$ \(\int_{a}^{x} K_{1}(x,t) u(t) dt\) + $\lambda_{2}$ \(\int_{a}^{b} K_{2}(x,t) u(t) dt\), \textbf{(2.3.1)}\\

and\\

u(x,t) = f(x,t) + $\lambda$ \(\int_{0}^{t} \int_{\Omega}F(x,t,\epsilon ,\tau , u(\epsilon ,\tau)) d\epsilon d\tau\), $(x,t) \in \Omega \times [0,T]$, \textbf{(2.3.2)}\\

where f(x,t) and $F(x,t,\epsilon , \tau,u(\epsilon , \tau))$ are analytic functions on $D = \Omega \times [0,T]$, and $\Omega$ is a closed subset of $R^n ,n =1 ,2,3$. It is interesting to note that (2.3.1) contains disjoint Volterra and Fredholm integral equations, whereas (2.3.2) contains mixed Volterra and Fredholm integral equations. Moreover, the unknownfunctions u(x) and u(x,t) appear inside and outside the integral signs. This is a characteristic feature of a second kind integral equation. If the unknown functions appear only inside the integral signs, the resulting equations are of ﬁrst kind, but will not be examined in this text. Examples of the two types are given by\\

$u(x) = 6x + 3x^2 + 2 -$ \(\int_{0}^{x} xu(t)dt - \int_{0}^{1} tu(t)dt\) ,\textbf{(2.3.3)}\\

and\\

$u(x,t) = x + t^3 + \frac{1}{2} t^2 - \frac{1}{2} t -$ \(\int_{0}^{t} \int_{0}^{1} (\tau - \epsilon)dEdT\)\textbf{(2.3.4)}\\

\newpage
\subsection{Singular Integral Equations}
Volterra integral equations of the first kind \\

$f(x) = \lambda$ \(\int_{g(x)}^{h(x)} K(x,t)u(t)dt\) \textbf{(2.4.1)}\\

or of the second kind\\

$u(x) = f(x) +$ \(\int_{g(x)}^{h(x)} K(x,t)u(t)dt\) \textbf{(2.4.2)}\\

are called singular if one of the limits of integration g(x), h(x) or both are inﬁnite. Moreover,the previous two equations are called singular if the kernel K(x,t) becomes unbounded at one or more points in the interval of integration. In this text we will focus our concern on equations of the form: \\

$f(x) =$ \(\int_{0}^{x} \frac{1}{(x - t)^ \alpha} u(t)dt\) ,    	$0 < \alpha < 1$ 		\textbf{(2.4.3)}\\

or of the second kind:\\

$u(x) = f(x) +$ \(\int_{0}^{x} \frac{1}{(x - t)^ \alpha} u(t)dt\) ,    	$0 < \alpha < 1$ 		\textbf{(2.4.4)}\\
The last two standard forms are called generalized Abel’s integral equation and weakly singular integral equations respectively. For $\alpha = \frac{1}{2}$ , the equation:\\

$f(x) =$ \(\int_{0}^{x} \frac{1}{\sqrt{x - t}} u(t)dt\)		\textbf{(2.4.5)}\\

is called the Abel’s singular integral equation. It is to be noted that the kernelin each equation become sinﬁnity at the upper limit $t = x$. Examplesof Abel’s integral equation, generalized Abel’s integral equation, and the weakly singular integral equation are given by\\

$\sqrt{x} =$ \(\int_{0}^{x} \frac{1}{\sqrt{x - t}} u(t)dt\)		\textbf{(2.4.6)}\\

$x^3 =$ \(\int_{0}^{x} \frac{1}{(x - t)^\frac{1}{3}} u(t)dt\)		\textbf{(2.4.7)}\\
and\\

$u(x) = 1 + \sqrt{x} +$ \(\int_{0}^{x} \frac{1}{(x - t)^\frac{1}{3}} u(t)dt\)		\textbf{(2.4.8)}\\

respectively.
\subsection{Method of Solving Volterra Integral Equations}
\textbf{1.)	The Adomian Decomposition Method}\\
The Adomian decomposition method (ADM) was introduced and developed by George Adomian in 1970s to 1990s and is well addressed in many references. A considerable amount of research work has been invested recently in applying this method to a wide class of linear and non-linear ordinary differential equations, partial differential equations and integral equations as well. The Adomian decomposition method consists of decomposing the unknown function u(x) of any equation into a sum of an infinite number of components defined by the decomposition series\\

$u(x) = \sum_{n=0}^{\infty}  u_n(x)$			. . . . . . 1\\

or equivalently\\

$u(x) = u_0(x) + u_1(x) + u_2(x) +$ . . . ,		. . . . . . .2\\

where the components$ u_n(x)$, $n\geq 0$ are to be determined  in a recursive manner. The decomposition method concerns itself with ﬁnding the components $u_0, u_1, u_2$, . . . individually.As willbeseenthroughthetext, thedetermination of these components can be achieved in an easy way through a recurrence relation that usually involves simple integrals that can be easily evaluated.
To establish the recurrence relation, we substitute (1) into the Volterra integral equation of the second kind to obtain\\

\(\sum_{n=0}^{\infty} U_{n}(x)\) = $f(x) + \lambda$ \(\int_{0}^{x} K(x,t)\) \(\sum_{n=0}^{\infty} U_{n}(t)\)dt,	. . . .3\\

or equivalently\\

$u_0(x) + u_1(x) + u_2(x) + . . . = f(x) + \lambda$ \(\int_{0}^{x} K(x,t) [u_0(t) + u_1(t) + . . .]dt\).		. . .  . .4\\

The zeroth component $u_0(x)$ is identiﬁed by all terms that are not included under the integral sign. Consequently, the components $u_j(x), j \geq 1$ of the unknown function u(x) are completely determined by setting the recurrence relation: \\

$u_o(x) = f(x)$,\\
$u_n+1(x) = \lambda$ \(\int_{0}^{x} K(x,t) u_n(t) dt\), 	$n \geq 0$,			. . . . . .5\\

that is equivalent to\\

$u_0(x) = f(x)$\\
$u_1(x) =  \lambda$ \(\int_{0}^{x} K(x,t) u_0(t) dt\),\\
$u_2(x) =  \lambda$ \(\int_{0}^{x} K(x,t) u_1(t) dt\),			. . . . . . . 6\\
$u_3(x) =  \lambda$ \(\int_{0}^{x} K(x,t) u_2(t) dt\),\\

and so on for the other components.
\par In view of (.  . . . .6), the components $u_0(x),u_1(x),u_2(x),u_3(x)$,... are completely determined. As a result, the solution u(x) of the Volterra integral equation of the second type in a series form is readily obtained by using the series assumption in (. . . . . 1). It is clearly seen that the decomposition method converted the integral equation into an elegant determination of computable components. It was formally shown by many researchers that if an exact solution exists for the problem,then the obtainedseriesconvergesveryrapidlyto that solution.The convergence concept of the decomposition series was thoroughly investigated by many researchers to conﬁrm the rapid convergence of the resulting series. However, for concrete problems, where a closed form solution is not obtainable, a truncated number of terms is usually used for numerical purposes. The more components we use the higher accuracy we obtain. \\

\textbf{2.)	The Modified Adomian Decomposition Method}\\
As shown before, the Adomian decomposition method provides the solution in an inﬁnite series of components. The components $u_j,j \geq 0$ are easily computed if the inhomogeneous term f(x) in the Volterra integral equation: \\

$u(x) = f(x) +  \lambda$ \(\int_{0}^{x} K(x,t) u(t) dt\)			. . . . . . . 7\\

consists of a polynomial. However, if the function f(x) consists of a combination of two or more of polynomials, trigonometric functions, hyperbolic functions, and others, the evaluation of the components $u_j,j \geq 0$ requires cumbersome work. A reliable modiﬁcation of the Adomian decomposition method was developed by Wazwaz. The modiﬁed decomposition method will facilitate the computational process and further accelerate the convergence of the series solution. The modiﬁed decomposition method will be applied, wherever it is appropriate, to all integral equations and diﬀerential equations of any order. It is interesting to note that the modiﬁeddecompositionmethoddependsmainlyonsplitting thefunction f(x)into two parts, therefore it cannot be used if the function f(x) consists of only one term.
To give a clear description of the technique, we recall that the standard Adomian decomposition method admits the use of the recurrence relation:\\

$u_o(x) = f(x)$,\\
$u_k+1(x) = \lambda$ \(\int_{0}^{x} K(x,t) u_k(t) dt\), 	$k \geq 0$,			. . . . . .8\\

where the solution u(x) is expressed by an inﬁnite sum of components deﬁned before by;\\

$u(x) = \sum_{n=0}^{\infty}  u_n(x)$			. . . . . . 9\\

In view of (. . . . . 8), the components $u_n(x),n\geq 0$ can be easily evaluated. The modiﬁed decomposition method introduces a slight variation to the recurrence relation (. . . . . . 8) that will lead to the determination of the components of u(x) in an easier and faster manner. For many cases, the function f(x) can be set as the sum of two partial functions, namely $f_1(x) and f_2(x)$. In other words, we can set \\

$f(x) = f_1(x) + f_2(x)$.			. . . . . .  .10\\

In view of (. . . . . . .10), we introduce a qualitative change in the formation of the recurrence relation (. . . . . . .8). To minimize the size of calculations, we identify the zeroth component $u_0(x)$ by one part of f(x), namely $f_1(x) orf_2(x)$. The other part of f(x) can be added to the component $u_1(x)$ among other terms. In other words, the modiﬁed decomposition method introduces the modiﬁed recurrence relation: \\

$u_0(x) = f_1(x)$\\
$u_1(x) = f_2(x) + \lambda$ \(\int_{0}^{x} K(x,t) u_0(t) dt\),\\
										. . . . . . .11\\
$u_k+1(x) = \lambda$ \(\int_{0}^{x} K(x,t) u_k(t) dt\), 	$k \geq 1$\\

This shows that the diﬀerence between the standard recurrence relation(. . . . .8) and the modiﬁed recurrence relation (. . .  . .11) rests only in the formation of the ﬁrst two components $u_0(x) and u_1(x)$ only. The other components $u_j,j \geq 2$ remain the same in the two recurrence relations. Although this variation in the formation of $u_0(x) and u_1(x)$ is slight, however it plays a major role in accelerating the convergence of the solution and in minimizing the size of computational work. Moreover,reducing the number of terms in $f_1(x)$ aﬀects not only the component $u_1(x)$, but also the other components as well. This result was conﬁrmed by several research works. Two important remarks related to the modiﬁed method can be made here. First, by proper selection of the functions $f_1(x) and f_2(x)$, the exact solution u(x) may be obtained by using very few iterations, and sometimes by evaluating only two components. The success of this modiﬁcation depends only on the proper choice of $f_1(x) and f_2(x)$, and this can be made through trials only. A rule that may help for the proper choice of $f_1(x) and f_2(x)$ could not be found yet. Second, if f(x) consistsof one term only, the standard decomposition method can be used in this case.
It is worth mentioning that the modiﬁed decomposition method will be used for Volterra and Fredholm integralequations, linear and nonlinear equations.\\

\textbf{3.)		The Noise Terms Phenomenon:}
It was shown before that the modiﬁed decomposition method presents a reliable tool for accelerating the computational work.However,aproperselection of f1(x) andf2(x) is essential for a successful use of this technique. A useful tool that will accelerate the convergence of the Adomian decomposition method is developed. The new technique depends mainly on the so-called noise terms phenomenon that demonstrates a fast convergence of the solution. The noise terms phenomenon can be used for all diﬀerential and integral equations. The noise terms, if existed between the components $u_0(x) and u_1(x)$, will provide the exact solution by using only the ﬁrst two iterations. In what follows, we outline the main concepts of the noise terms : \\
\par 1. The noise terms are deﬁned as the identical terms with opposite signs that arise in the components $u_0(x) and u_1(x)$. Other noise terms may appear between other components. As stated above, these identical terms with opposite signs may exist for some equations, and may not appear for other equations.
\par 2. By canceling the noise terms between $u_0(x) and u_1(x)$, even though $u_1(x)$ contains further terms, the remaining non-canceled terms of $u_0(x)$ may give the exact solution of the integral equation. The appearance of the noise terms between $u_0(x) and u_1(x)$ is not always suﬃcient to obtain the exact solution by canceling these noise terms. Therefore, it is necessary to show that the non-canceled terms of $u_0(x)$ satisfy the given integral equation. On the other hand, if the non-canceled terms of $u_0(x)$ did not satisfy the given integral equation, or the noise terms did not appear between $u_0(x) and u_1(x)$, then it is necessary to determine more components of u(x) to determine the solution in a series form as presented before. 
\par 3.It was formally shown that the noise terms appear for speciﬁc cases of inhomogeneous diﬀerential and integral equations, whereas homogeneous equations do not give rise to noise terms. The conclusion about the selfcanceling noise terms was based on solving several speciﬁc diﬀerential and integral models. However, a proof for this conclusion was not given.\\

A useful summary about the noise terms phenomenon can be drawn as follows:\\
\par 1. The noise terms are deﬁned as the identical terms with opposite signs that may appear in the components $u_0(x) and u_1(x)$ and in the other components as well.
\par 2. The noise terms appear only for speciﬁc types of inhomogeneous equations whereas noise terms do not appear for homogeneous equations.
\par 3. Noise terms may appear if the exact solution of the equation is part of the zeroth component $u_0(x)$. \\
\textbf{4.)		The Laplace Transform Method:}
The Laplace transform method is a powerful technique that can be used for solving initial value problems and integral equations as well. In the convolution theorem for the Laplace transform, it was stated that if the kernel K(x,t) of the integral equation: \\

$u(x) = f(x) + \lambda$ \(\int_{0}^{x} K(x,t) u(t) dt\)\\

depends on the difference $x−t$, then it is called a difference kernel. Examples of the difference kernel are $e^{x-t}$ ,$cos(x - t)$ ,$sin(x - t)$. The integral equation can thus be expressed as \\

$u(x) = f(x) + \lambda$ \(\int_{0}^{x} K(x - t) u(t) dt\)\\

Consider two functions $f_1(x)$ and $f_2(x)$ that possess the conditions needed for the existence of Laplace transform for each. Let the Laplace transforms for the functions $f_1(x)$ and $f_2(x)$ be given by: \\

$\emph{L}{f_1(x)} = F_1(s)$,\\
$\emph{L}{f_2(x)} = F_2(s)$.\\
The Laplace convolution product of these two functions is deﬁned by \\

$(f_1 * f_2)(x) =$ \(\int_{0}^{x} f_1(x - t) f_2(t) dt\)\\
or\\
$(f_2 * f_1)(x) =$ \(\int_{0}^{x} f_2(x - t) f_1(t) dt\)\\
Recall that;\\
$(f_1 * f_2)(x) = (f_2 * f_1)(x)$\\

We can easily show that the Laplace transform of the convolution product $(f1 * f2)(x)$ is given by \\

$\emph{L}{(f_1 * f_2)(x)} =$ \emph{L}{\(\int_{0}^{x} f_1(x - t) f_2(t) dt\) $= F_1(s)F_2(s)$
\newpage
\section{Methodology}
\subsection{Laplace Transform}
In mathematics, the Laplace transform, named after its inventor Pierre-Simon Laplace, is an integral transform that converts a function of a real variable \textbf{t} (often time) to a function of a complex variable \textbf{s} (complex frequency). The transform has many applications in science and engineering because it is a tool for solving differential equations. In particular, it transforms linear differential equations into algebraic equations and convolution into multiplication.

For suitable functions f, the Laplace transform is the integral;\\

\emph{L}{f}(s) = \(\int_{0}^{\infty} f(t) e^{-st} dt\)\\

The Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory. Laplace wrote extensively about the use of generating functions in \emph{Essai philosophique sur les probabilités} (1814), and the integral form of the Laplace transform evolved naturally as a result.

Laplace's use of generating functions was similar to what is now known as the z-transform, and he gave little attention to the continuous variable case which was discussed by Niels Henrik Abel. The theory was further developed in the 19th and early 20th centuries by Mathias Lerch, Oliver Heaviside, and Thomas Bromwich.

The current widespread use of the transform (mainly in engineering) came about during and soon after World War II, replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by Gustav Doetsch, to whom the name Laplace Transform is apparently due.

From 1744, Leonhard Euler investigated integrals of the form;\\

$z =$ \(\int X(x) e^{ax} dx\)		and		$z =$ \(\int X(x)x^A dx\)\\

as solutions of differential equations, but did not pursue the matter very far. Joseph Louis Lagrange was an admirer of Euler and, in his work on integrating probability density functions, investigated expressions of the form;\\

\(\int X(x) e^{-ax} a^x dx\)\\

which some modern historians have interpreted within modern Laplace transform theory.

These types of integrals seem first to have attracted Laplace's attention in 1782, where he was following in the spirit of Euler in using the integrals themselves as solutions of equations. However, in 1785, Laplace took the critical step forward when, rather than simply looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form;\\

\(\int x^s \phi (x) dx\),\\

akin to a Mellin transform, to transform the whole of a difference equation, in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.

Laplace also recognised that Joseph Fourier's method of Fourier series for solving the diffusion equation could only apply to a limited region of space, because those solutions were periodic. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.\\

The Laplace transform of a function f(t), defined for all real numbers $t \geq 0$, is the function F(s), which is a unilateral transform defined by;\\

$F(s) =$ \(\int_{0}^{\infty} f(t)e^{-st}dt\)\\

where s is a complex number frequency parameter\\

$s = \mu + i\omega$,\\

with real numbers $\mu$ and $\omega$\\

An alternate notation for the Laplace transform is $\mathcal{L} (f)$ instead of F.

The meaning of the integral depends on types of functions of interest. A necessary condition for existence of the integral is that f must be locally integrable on [0, $\infty$). For locally integrable functions that decay at infinity or are of exponential type ($|f(t)| \leq Ae^{B|t|}$), the integral can be understood to be a (proper) Lebesgue integral. However, for many applications it is necessary to regard it as a conditionally convergent improper integral at ∞. Still more generally, the integral can be understood in a weak sense, and this is dealt with below.

One can define the Laplace transform of a finite Borel measure μ by the Lebesgue integral;\\

$\mathcal{L} (f) =$ \(\int_{[0,\infty)} e^{-st} d\nu(t)\)\\

An important special case is where μ is a probability measure, for example, the Dirac delta function. In operational calculus, the Laplace transform of a measure is often treated as though the measure came from a probability density function f. In that case, to avoid potential confusion, one often writes\\

$\mathcal{L} (f) =$ \(\int_{0^-}^{\infty} f(t)e^{-st}dt\),\\

where the lower limit of $0^-$ is shorthand notation for\\

$\lim_{\epsilon \to 0^+}$ \(\int_{-\epsilon}^{\infty} .\)\\

This limit emphasizes that any point mass located at 0 is entirely captured by the Laplace transform. Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the Laplace–Stieltjes transform.
The Laplace transform can be used to solve differential equations. Besides
being a different and efficient alternative to variation of parameters
and undetermined coefficients, the Laplace method is particularly advantageous for input terms that are piecewise-defined, periodic or impulsive.
\subsection{Differentiation and the Laplace Transform}
In this section, we explore how the Laplace transform interacts with the basic operators of
calculus: differentiation and integration. The greatest interest will be in the first identity that
we will derive. This relates the transform of a derivative of a function to the transform of
the original function, and will allow us to convert many initial-value problems to easily solved
algebraic equations. But there are other useful relations involving the Laplace transform and
either differentiation or integration. So we’ll look at them, too.

\textbf{Transforms of Derivatives}

To see how the Laplace transform can convert a differential equation to a simple algebraic equation, let us examine how the transform of a function’s derivative,\\

$\mathcal{L} [f'(t)]|_{s} = \mathcal{L} [\frac{df}{dt}]|_{s}$ = \(\int_{0}^{\infty} \frac{df}{dt} e^{-st}dt\) = \(\int_{0}^{\infty} e^{-st} \frac{df}{dt} dt\)\\

is related to the corresponding transform of the original function,

$F(s) = \mathcal{L} [f(t)]|_{s}$ = \(\int_{0}^{\infty} f(t)e^{-st} dt\)\\

The last formula above for $\mathcal{L} [f'(t)]$ clearly suggests using integration by parts, and to ensure
that this integration by parts is valid, we need to assume f is continuous on $[0,\infty)$ and f' is
at least piecewise continuous on $(0,\infty)$. Assuming this,

$\mathcal{L} [f'(t)]|_{s}$ = \(\int_{0}^{\infty} e^{-st} \frac{df}{dt} dt\)\\

where, $u = e^{-st}$, and $dv = \frac{df}{dt} dt$\\

$= uv|_{t = 0}^{\infty}$ - \(\int_{0}^{\infty} vdu\)\\

$= e^{-st} f(t)|_{t=0}^{\infty}$ - \(\int_{0}^{\infty} f(t)[-se^{-st}]dt\)\\

$= \lim_{t \to \infty} e^{-st} f(t) - e^{-s(0)}f(0)$ - \(\int_{0}^{\infty} f(t)[-se^{-st}]dt\)\\

$= \lim_{t \to \infty} e^{-st} f(t) - f(0)$ + s \(\int_{0}^{\infty} f(t)e^{-st}dt\)\\

Now, if f is of exponential order $s_0$, then\\

$\lim_{t \to \infty} e^{-st} f(t) = 0$		whenever $s>s_0$\\

and\\

$F(s) = \mathcal{L}[f(t)]|_s$ = \(\int_{0}^{\infty} f(t)e^{-st}dt\)		exists for $s>s_0$\\

Thus, continuing the above computations for $\mathcal{L}[f'(t)]$ with $s>s_0$, we find that \\

$\mathcal{L}[f'(t)]|_s = \lim_{t \to \infty} e^{-st} f(t) - f(0)$ + s \(\int_{0}^{\infty} f(t)e^{-st}dt\)\\

$= 0 - f(0) + s\mathcal{L}[f(t)]|_s$\\

which is a little mor conveniently written as\\

$\mathcal{L}[f'(t)]|_s = s\mathcal{L}[f(t)]|_s - f(0)$\\

or even as,\\

$\mathcal{L}[f'(t)]|_s = sF(s) - f(0)$\\

This will be a very useful result, well worth preservingin a theorem.\\

 \textbf{THEOREM}\\
Let $F = \mathcal{L}[f]$ where f is a contionous function of exponential order $s_0$ on $[0, \infty)$. If f' is at least piecewise continous on $(0, \infty)$, then\\

$\mathcal{L}[f'(t)]|_s = sF(s) - f(0)$		for $s>s_0$\\.

Extending these deivatives to formulas for the the transforms of higher derivatives is easy. First, for convenience, rewrite the equation above as\\

$\mathcal{L}[g'(t)]|_s = s\mathcal{L}[g(t)]|_s - g(0)$\\

or equivalently as\\

$\mathcal{L}[\frac{dg}{dt}]|_s = s\mathcal{L}[g(t)]|_s - g(0)$\\

(Keep in mind that this assumes g is a continuous function of exponential order, g' is piecewise continuous and s is larger than the order of g .) Now we simply apply this equation with $g = f'$, $g = f"$, etc. Assuming all the functions are sufficiently continuous and are of exponential order,
we see that\\

$\mathcal{L}[f"(t)]|_s = \mathcal{L}[\frac{df'}{dt}]|_s = s\mathcal{L}[f'(t)]|_s - f'(0)$\\

$= s[sF(s) - f(0)] - f'(0)$\\

$= s^2F(s) - sf(0) - f'(0)$.\\

Using this, we then see that\\

$\mathcal{L}[f"'(t)]|_s = \mathcal{L}[\frac{df''}{dt}]|_s = s\mathcal{L}[f''(t)]|_s - f''(0)$\\

$= s[s^2F(s) - sf(0) - f'(0)] - f"(0)$\\

$= s^3F(s) - s^2f(0) - sf'(0) - f"(0)$.\\

\textbf{COROLLARY}\\
Let $F = \mathcal{L}[f]$ where f is a contionous function of exponential order $s_0$ on $[0, \infty)$. If f' is at least piecewise continous on $(0, \infty)$, then\\

$\mathcal{L}[f'(t)]|_s = sF(s) - f(0)$		for $s>s_0$\\.

If in addition, f' is a continous function of exponential order $s_0$, and f" is at least piecewise continous, then\\

$\mathcal{L}[f"(t)]|_s = s^2F(s) - sf(0) - f'(0)$.\\

More generally, if $f, f', f", ...,and f^{(n-1)}$ are all continous functions of exponential order $s_0$ on $[0, \infty)$ for some positive integer n, and $f^{(n)}$ is at least piecewise continous on $(0, \infty)$, then, for $s>s_0$.\\

$\mathcal{L}[f"(t)]|_s = s^n F(s) - s^{n-1} f(0) - s^{n-2}f'(0) - s^{n-3}f"(0) - ... - sf^{(n-2)}(0) - f^{(n-1)}(0)$.

\subsection{Inverse Laplace Transform}
Two integrable functions have the same Laplace transform only if they differ on a set of Lebesgue measure zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a one-to-one mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range.

Typical function spaces in which this is true include the spaces of bounded continuous functions, the space $L^\infty$(0 , $\infty$), or more generally tempered distributions on (0 , $\infty$). The Laplace transform is also defined and injective for suitable spaces of tempered distributions.

In these cases, the image of the Laplace transform lives in a space of analytic functions in the region of convergence. The inverse Laplace transform is given by the following complex integral, which is known by various names (the Bromwich integral, the Fourier–Mellin integral, and Mellin's inverse formula):\\

$f(t) = \mathcal{L}^{-1} [f(t)] = \frac{1}{2\pi i} \lim_{T \to \infty}$ \(\int_{\gamma - iT}^{\gamma + iT} e^{st} F(s) ds\)\\

\subsection{Properties of Laplace Transforms}
From the deﬁnition of the Laplace transform given in the previous subsection, we can easily derive the following properties of the Laplace transforms:
\par \textbf{1.)	Constant Multiple:}\\
	$\mathcal{L}[af(x)] = a \mathcal{L}[f(x)]$, a is a constant.\\
For example:\\
	$\mathcal{L}[4e^x] = 4 \mathcal{L}[e^x] = \frac{4}{s - 1}$.\\

\par \textbf{2.)	Linearity Property:}\\
	$\mathcal{L}[af(x) + bg(x)] = a \mathcal{L}[f(x)] +  b \mathcal{L}[g(x)]$, a,b is a constant.\\
For example:\\
	$\mathcal{L}[4x + 3x^2] = 4 \mathcal{L}[x] + 3 \mathcal{L}[x^2]= \frac{4}{s ^2} + \frac{6}{s^3}$.\\
\par \textbf{3.)	Multiplication by:}\\
	$\mathcal{L}[xf(x)] = - \frac{d}{ds} \mathcal{L}[f(x)] = -F'(s)$.\\
For example:\\
	$\mathcal{L}[xsinx] = - \frac{d}{ds} \mathcal{L}[sinx] = - \frac{d}{ds} (\frac{1}{s^2 + 1}) = \frac{2s}{(s^2 + 1)^2}$.\\

To use the Laplace transform L for solving initial value problems or integral equations, we use the following table of elementary Laplace transforms as shown below:\\
\begin{tabular}{| l | c | } \hline 
f(x) & $F(s) = \mathcal{L}[f(x)] =$ \(\int_{0}^{\infty} e^ax f(x) dx\)\\
\hline
c & $\frac{c}{s}, s > 0$\\
x & $\frac{1}{s^2}, s > 0$\\
$x^n$ & $\frac{n!}{s^{n +1}} = \frac{\Gamma (n + 1)}{s^{n + 1}}, s \geq 0, Re$ $n > -1$\\
$e^ax$ & $\frac{1}{s - a}, s > a$\\
$sin ax$ & $\frac{a}{s^2 + a^2}$\\ 
$cos ax$ & $\frac{s}{s^2 + a^2}$\\ 
$sin^2 ax$ & $\frac{2a^2}{s(s^2 + 4 a^2)}, Re(s) > |Im(a)|$\\ 
$cos^2 ax$ & $\frac{s^2 + 2a^2}{s(s^2 + 4 a^2)}, Re(s) > |Im(a)|$\\ 
$xsin ax$ & $\frac{2as}{(s^2 + a^2)^2}$\\ 
$xcos ax$ & $\frac{s^2 - a^2}{(s^2 + a^2)^2}$\\ 
$sinh ax$ & $\frac{a}{s^2 - a^2}, s \geq |a|$\\ 
$cosh ax$ & $\frac{s}{s^2 - a^2}, s \geq |a|$\\ 
$sinh^2 ax$ & $\frac{2a^2}{s(s^2 - 4 a^2)}, Re(s) > |Im(a)|$\\ 
$cosh^2 ax$ & $\frac{s^2 - 2a^2}{s(s^2 - 4 a^2)}, Re(s) > |Im(a)|$\\ 
$xsinh ax$ & $\frac{2as}{(s^2 - a^2)^2}, s > |a|$\\ 
$xcosh ax$ & $\frac{s^2 + a^2}{(s^2 - a^2)^2}, s > |a|$\\ 
$x^n e^ax$ & $\frac{n!}{(s - a)^{n + 1}}, s > a$, n is a positive integer\\ 
$e^ax sinbx$ & $\frac{b}{(s - a)^2) + b^2}, s > a$\\ 
$e^ax cosbx$ & $\frac{s - a}{(s - a)^2) + b^2}, s > a$\\ 
$e^ax sinhbx$ & $\frac{b}{(s - a)^2) - b^2}, s > a$\\ 
$e^ax coshbx$ & $\frac{s - a}{(s - a)^2) - b^2}, s > a$\\ 
\hline
\end{tabular}
\\
\par \textbf{4.)	Laplace Transforms of Derivatives:}\\
	$\mathcal{L}[f'(x)] = s \mathcal{L}[f(x)] - f(0)$,\\
	$\mathcal{L}[f''(x)] = s^2 \mathcal{L}[f(x)] - sf(0) - f'(0)$,\\
	$\mathcal{L}[f'''(x)] = s^3 \mathcal{L}[f(x)] - s^2f(0) - sf'(0) - f''(0)$,\\
			.
			.
			.\\
	$\mathcal{L}[f^{(n)} (x)] = s^n \mathcal{L}[f(x)] - s^{n - 1} f(0) -... - sf^{(n - 2)}(0) - f^{(n - 1)}(0)$,\\

	\par \textbf{5.)	Inverse Laplace Transforms:}\\
If the Laplace transform of f(x) is F(s), then we say that the inverse Laplace transform of F(s) is f(x). In other words, we write;\\
$\mathcal{L}^{-1}[F(s)] = f(x)$,\\
where $\mathcal{L}^{-1}$ is the operator of the inverse Laplace transform. The linearity property holds also for the inverse Laplace transform. This means that ;\\
$\mathcal{L}^{-1}[aF(s) + bG(s)] = a \mathcal{L}^{-1}[F(s)] +  a \mathcal{L}^{-1}[G(s)]$.\\

\par 								$= af(x) + bg(x)$.\\
\newpage
\section{Numerical Example}


\textbf{1.} $U(x) = 1 - x^2 + x^3$ + \(\int_{0}^{x} [(x - t) U(t) + (x - t)V(t)]dt\)\\
\par$V(x) = 1 - x^3 - \frac{1}{10} x^5$ + \(\int_{0}^{x} [(x - t) U(t) - (x - t)V(t)]dt\)\\

Notice that the kernels $K_1(x − t) = K_2(x − t) = x − t$. Taking Laplace transform of both sides of each equation gives;\\

$U(s) = \mathcal{L}[u(x)] = \mathcal{L}[1 - x^2 + x^3] + \mathcal{L}[(x - t) * u(x) + (x - t) * v(x)]$,\\

$V(s) = \mathcal{L}[v(x)] = \mathcal{L}[1 - x^3 - \frac{1}{10}x^5] + \mathcal{L}[(x - t) * u(x) - (x - t) * v(x)]$,\\

This in turn gives\\

$U(s) = \frac{1}{s} - \frac{2}{s^3} + \frac{6}{s^4} + \frac{1}{s^2}U(s) + \frac{1}{s^2}V(s)$,\\

$V(s) = \frac{1}{s} - \frac{6}{s^4} - \frac{12}{s^6} + \frac{1}{s^2} U(s) - \frac{1}{s^2}V(s)$.\\

Solving this system of equations of equations for U(s) and V(s) gives\\

$U(s) = \frac{1}{s} + \frac{3!}{s^4}$,\\

$V(s) = \frac{1}{s} - \frac{3!}{s^4}$.\\

By taking the Inverse Laplace transform of the sides of each of the equation above gives the exact solutions given by;\\

$(u(x), v(x)) = (1 + x^3, 1 - x^3)$.\\

\textbf{2.} $U(x) = 1 - 2x + sinx$ + \(\int_{0}^{x} [U(t) + V(t)]dt\)\\
\par$V(x) = 1 - x^2 - sinx$ + \(\int_{0}^{x} [tU(t) - tV(t)]dt\)\\

 Taking the Laplace transform of both sides of each equation gives;\\

$U(s) = \mathcal{L}[u(x)] = \mathcal{L}[1 - 2x + sinx] + \mathcal{L}[u(x) + v(x)]$,\\

$V(s) = \mathcal{L}[v(x)] = \mathcal{L}[1 - x^2 - sinx] + \mathcal{L}[u(x) - v(x)]$.\\

This in turn gives\\

$U(s) = \frac{1}{s} - \frac{2}{s^2} + \frac{1}{1 + s^2} + U(s) + V(s)$,\\

$V(s) = \frac{1}{s} - \frac{2}{s^3} - \frac{1}{1 + s^2} + U(s) - V(s)$,\\

Solving this system of equations of equations for U(s) and V(s) gives\\

$U(s) = \frac{1}{s} + \frac{1}{1 + s^2}$,\\

$V(s) = \frac{1}{s} - \frac{1}{1 + s^2}$.\\

By taking the Inverse Laplace transform of the sides of each of the equation above gives the exact solutions given by;\\

$(u(x), v(x)) =(1 + sinx, 1 - sinx)$.\\

\textbf{3.} $U(x) = cosx - sinx$ + \(\int_{0}^{x} [cos(x - t)U(t) + sin(x - t)V(t)]dt\)\\
\par$V(x) =  sinx - xsinx$ + \(\int_{0}^{x} [sin(x - t)U(t) - cos(x - t)V(t)]dt\)\\

 Taking the Laplace transform of both sides of each equation gives;\\

$U(s) = \mathcal{L}[u(x)] = \mathcal{L}[cosx - sinx] + \mathcal{L}[cos(x - t) * u(x) + sin(x - t) * v(x)]$,\\

$V(s) = \mathcal{L}[v(x)] = \mathcal{L}[sinx - xsinx] + \mathcal{L}[sin(x - t) * u(x) - cos(x - t) * v(x)]$.\\

This in turn gives\\

$U(s) = \frac{s}{1 + s^2} - \frac{1}{1 + s^2} + \frac{s}{1 + s^2}U(s) + \frac{1}{1 + s^2}V(s)$,\\

$V(s) = \frac{1}{1 + s^2} - \frac{2s}{(1 + s^2)^2} + \frac{1}{1 + s^2}U(s) + \frac{s}{1 + s^2}V(s)$,\\

or equivalently\\

$(1 - \frac{s}{1+s^2})U(s) - \frac{1}{1+s^2}V(s) = \frac{s}{1 + s^2} - \frac{1}{1 + s^2}$\\

$(1 - \frac{s}{1+s^2})V(s) - \frac{1}{1+s^2}U(s) = \frac{1}{1 + s^2} - \frac{2s}{(1 + s^2)^2}$\\

Solving this system of equations of equations for U(s) and V(s) gives\\

$U(s) = \frac{s}{1+s^2}$,\\

$V(s) = \frac{1}{1+s^2}$,\\

By taking the Inverse Laplace transform of the sides of each of the equation above gives the exact solutions given by;\\

$(u(x), v(x)) =(cosx, sinx)$.\\

\textbf{4.} $$.\\

\newpage
\section{Conclusion}
The Laplace transform is used frequently in engineering and physics; the output of a linear time-invariant system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. The Laplace transform is invertible on a large class of functions. Given a simple mathematical or functional description of an input or output to a system, the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.

The Laplace transform can also be used to solve differential equations and is used extensively in mechanical engineering and electrical engineering. The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra. The original differential equation can then be solved by applying the inverse Laplace transform. English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.


\textbf{Evaluating improper integrals}

Let $\mathcal{L}[f(t)] = F(s)$. Then,

$\mathcal{L}[\frac{f(t)}{t}]$ = \(\int_{0}^{\infty} \frac{f(t)}{t} e^{-st}dt\) = \(\int_{s}^{\infty} F(p) dp\).\\

In the limit $s \to 0$, one gets


\(\int_{0}^{\infty} \frac{f(t)}{t}dt\) = \(\int_{0}^{\infty} F(p)dp\)\\

provided that the interchange of limits can be justified. This is often possible as a consequence of the final value theorm. Even when the interchange cannot be justified the calculation can be suggestive. Ffor example, with $a \neq 0 \neq b$, proceeding formally one has

\(\int_{0}^{\infty} \frac{cos(at) - cos(bt)}{t} dt\) = \(\int_{0}^{\infty} (\frac{p}{p^2 + a^2} - \frac{p}{p^2 + b^2}) dp\)\\

$= [\frac{1}{2} ln \frac{p^2 + a^2}{p^2 + b^2}]_{0}^{\infty} = \frac{1}{2} ln \frac{b^2}{a^2} = ln|\frac{b}{a}|$.\\

The validity of this identity can be proved by other means. It is an example of a Frullani integral.

Another example is Dirichlet integral.


\textbf{Partial fraction expansion}

Consider a linear time-invariant system with transfer function


$H(s) = \frac{1}{(s + \alpha)(s + \beta)}$\\

The impulse response is simply the inverse Laplace transform of this transfer function:

$h(t)=\mathcal {L}^{-1}[H(s)]$\\

To evaluate this inverse transform, we begin by expanding H(s) using the method of partial fraction expansion,


$\frac{1}{(s + \alpha)(s + \beta)} = \frac{P}{s + \alpha} + \frac{R}{s + \beta}$.\\

The unknown constants P and R are the residues located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that singularity to the transfer function's overall shape.

By the residue theorem, the inverse Laplace transform depends only upon the poles and their residues. To find the residue P, we multiply both sides of the equation by $s + \alpha$ to get


$\frac{1}{s + \beta} = P + \frac{R(s + \alpha)}{s + \beta}$.\\

Then by letting $s =-\alpha$, the contribution from R vanishes and all that is left is 

$P = \frac{1}{s + \beta}|_{s=-\alpha} = \frac{1}{\beta - \alpha}$.\\

Similarly, the residue R is given by


$R = \frac{1}{s + \alpha}|_{s=-\beta} = \frac{1}{\alpha - \beta}$.\\

Note that 

$R = \frac{-1}{\beta - \alpha} = -P$\\

and so the substitution of R and P into the expanded expression for H(s) gives

$H(s) = (\frac{1}{\beta - \alpha}) . (\frac{1}{s + \alpha} - \frac{1}{s + \beta})$.\\

Finally, using the linearity property and the known transform for exponential decay, we can take the inverse Laplace transform of H(s) to obtain


$h(t)=\mathcal {L}^{-1}[H(s)] = \frac{1}{\beta - \alpha} (e^{-\alpha t} - e^{-\beta t})$,\\

which is the impulse response of the system.


\textbf{Convolution}


The same result can be achieved using the convolution property as if the system is a series of filters with transfer functions of $\frac{1}{s + b}$ and $\frac{1}{s + b}$. That is, the inverse of


$H(s) = \frac{1}{(s + a)(s + b)} = \frac{1}{s + a} . \frac{1}{s + b}$\\

is


$\mathcal {L}^{-1}[\frac{1}{s + a}] * \mathcal {L}^{-1}[\frac{1}{s + b}] = e^{-at} * e^{-bt}$ = \(\int_{0}^{t} e^{-ax} e^{-b(t-x)}dx\) = $\frac{e^{-at} - e^{-bt}}{b - a}$.
\newpage
\begin{thebibliography}{99}
\bibitem{Efficient solution of a partial integro-differential equation in finance}
Sachs, E.W.; Strauss, A. K. (2008-11-01) \emph{Efficient solution of a partial integro-differential equation in finance}, Applied Numerical Mathematics.58 (11): 1687 - 1703.

\bibitem{Hermann17}
Brunner Hermann (2017)
\emph{Volterra Integral Equations: An introduction to Theory and Applications}, Cambridge Monographs on Applied and Computational Mathematics.
Cambridge, UK: Cambridge University Press.

\bibitem{Polyanin08}
Polyanin, Andrei D.; Manzhirov, Alexander V. (2008).
\emph{Handbook of Integral Equations (2nd ed.)}. Boca Raton, FL: Chapman and Hall/CRC.

\bibitem{wazwaz97}
Abdul- Majid Wazwaz (1997)
\emph{A First Course in Integral Equations}, World Scientific.

\bibitem{thangavel05}
K. Thangavel,P. Balasubramaniam (2005).
\emph{Computational Mathematics}

\bibitem{Upadhyay15}
Subrahamanyam Upadhyay and K. N. Rai (2015).
\emph{Integral equation: An introduction}
\end{thebibliography}
\end{document}